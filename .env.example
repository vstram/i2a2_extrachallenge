# Environment Configuration for AI Analytics Chatbot
# Copy this file to .env and configure your specific values

# Application Environment
# Options: development, testing, staging, production
ENVIRONMENT=development

# LLM Configuration
# OpenAI Settings
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.1

# Ollama Settings (for local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:latest

# Default LLM Provider
# Options: openai, ollama
LLM_PROVIDER=openai

# Data Processing Configuration
CHUNK_SIZE=10000
MAX_FILE_SIZE_MB=150
MAX_ROWS_SAMPLE=50000

# Cache Configuration
CACHE_ENABLED=true
CACHE_MAX_SIZE_MB=500
CACHE_DIR=cache

# Logging Configuration
LOG_LEVEL=INFO
LOG_DIR=logs

# UI Configuration
PAGE_TITLE=AI Analytics Chatbot
ENABLE_CHARTS=true

# Security Configuration
MAX_UPLOAD_SIZE_MB=150

# Performance Monitoring
ENABLE_MONITORING=true

# Database Configuration (if needed for future extensions)
# DATABASE_URL=sqlite:///app.db
# DATABASE_POOL_SIZE=5

# External Service URLs (if needed)
# WEBHOOK_URL=https://your-webhook-endpoint.com
# NOTIFICATION_EMAIL=admin@yourcompany.com

# Feature Flags (for gradual rollouts)
# ENABLE_EXPERIMENTAL_FEATURES=false
# ENABLE_ADVANCED_ANALYTICS=true
# ENABLE_EXPORT_FEATURES=true

# Performance Tuning
# WORKER_PROCESSES=4
# WORKER_THREADS=2
# REQUEST_TIMEOUT=300

# Development/Debug Settings
# DEBUG_MODE=false
# PROFILING_ENABLED=false
# MOCK_LLM_RESPONSES=false